{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12c6DSiU4Rq3P4ZxziKxzrL5LmMBrzjrJX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1HLoD9E4SDFFPDiYfNYnkBLQ85Y51J3Zb1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1FvzCLoTPGANNjWoUo6jUGuAG3wg1w4YjR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15ubicBBWFnvoZLT7GiU2qxjRaKJPdkDMG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8708816</th>\n",
       "      <td>13dJEWNK55L5Zbh8ZVqpvmpritkEYHD1nE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8708817</th>\n",
       "      <td>1GA1vXcj4UMwcgr7nBftkpxXE6RrBwwm2M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8708818</th>\n",
       "      <td>1DrJbVsNJDweTQgKAwrBNyKuvtFBS6iKNK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8708819</th>\n",
       "      <td>1Mtcwd8jsoMYdwBxcybBkFWm1NNCRMRToh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8708820</th>\n",
       "      <td>1H3kPaxJbJoQBpKeaZ8MM781WkMjx3Nge1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8708821 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          hash\n",
       "address_id                                    \n",
       "0           1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa\n",
       "1           12c6DSiU4Rq3P4ZxziKxzrL5LmMBrzjrJX\n",
       "2           1HLoD9E4SDFFPDiYfNYnkBLQ85Y51J3Zb1\n",
       "3           1FvzCLoTPGANNjWoUo6jUGuAG3wg1w4YjR\n",
       "4           15ubicBBWFnvoZLT7GiU2qxjRaKJPdkDMG\n",
       "...                                        ...\n",
       "8708816     13dJEWNK55L5Zbh8ZVqpvmpritkEYHD1nE\n",
       "8708817     1GA1vXcj4UMwcgr7nBftkpxXE6RrBwwm2M\n",
       "8708818     1DrJbVsNJDweTQgKAwrBNyKuvtFBS6iKNK\n",
       "8708819     1Mtcwd8jsoMYdwBxcybBkFWm1NNCRMRToh\n",
       "8708820     1H3kPaxJbJoQBpKeaZ8MM781WkMjx3Nge1\n",
       "\n",
       "[8708821 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "inputs= pd.read_csv(\"./dataset/inputs.csv\",names=['txid','prev_tx_id','prev_tx_pos'])\n",
    "outputs = pd.read_csv(\"./dataset/outputs.csv\",names=['txid','position','address_id','amount','script_type'])\n",
    "outputs=outputs.astype({\n",
    "    'script_type':'uint8',\n",
    "})\n",
    "transactions = pd.read_csv(\"./dataset/transactions.csv\",names=['timestamp','block_id','txid','is_coinbase','fee'])\n",
    "transactions= transactions.astype({\n",
    "    'is_coinbase':'bool',\n",
    "})\n",
    "map=pd.read_csv(\"./dataset/mapAddr2Ids8708820.csv\",names=['hash','address_id'])\n",
    "map.set_index('address_id')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Analisi generali dei dati della blockchain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## distribuzione transazioni per blocco\n",
    "distribuzione del numero di transazioni per blocco (occupazione del blocco), nell’intero\n",
    "periodo temporale considerato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_distribution=transactions.groupby(['block_id']).count()[['timestamp']]\n",
    "res=pd.DataFrame(columns=['blocks'])\n",
    "res.index.name='value'\n",
    "for (i,g) in tx_distribution.groupby(['timestamp']):\n",
    "    res.loc[i]=len(g)\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.scatter(np.log(res.index),res['blocks'],s=1)\n",
    "plt.xlabel('numero di transazioni')\n",
    "plt.ylabel('blocchi')\n",
    "\n",
    "#TODO : fix display of data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evoluzione dell'occupazione dei blocchi nel tempo\n",
    "evoluzione dell'occupazione dei blocchi nel tempo, considerando intervalli temporali di due\n",
    "mesi.(media dell'occupazione di blocchi su archi temporali di 2 mesi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import pairwise\n",
    "\n",
    "transactions['date']=pd.to_datetime(transactions['timestamp'],unit='s')\n",
    "month_transactions=[]\n",
    "month_group=transactions.groupby([transactions['date'].dt.year,transactions['date'].dt.month])\n",
    "\n",
    "average_tx=pd.DataFrame(columns=['average_tx'])\n",
    "\n",
    "for (k1,k2) in pairwise(month_group.groups.keys()):\n",
    "    months_df=pd.concat([month_group.get_group(k1),month_group.get_group(k2)])\n",
    "    y,m1=k1\n",
    "    _,m2=k2\n",
    "    average_tx.loc[f\"{y}-{m1}/{m2}\"]=months_df.groupby(['block_id']).count()['timestamp'].mean()\n",
    "average_tx.plot(kind='bar',figsize=(14,5))\n",
    "# TODO: fix display of data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ammontare degli ultimi UTXO rimanenti\n",
    "ammontare totale degli UTXO al momento dell’ultima transazione registrata nella\n",
    "blockchain considerata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spent_utxos=outputs.merge(inputs,how='inner',left_on=['txid','position'],right_on=['prev_tx_id','prev_tx_pos'])\n",
    "unspent_utxos_amount=sum(outputs.amount)-sum(spent_utxos.amount)\n",
    "unspent_utxos_amount"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## durata media di un UTXO prima di essere speso\n",
    "distribuzione degli intervalli di tempo che intercorrono tra la transazione che genera un\n",
    "valore in output (UTXO) e quella che lo consuma, per gli output spesi nel periodo\n",
    "considerato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a=inputs.merge(transactions[['txid','timestamp']],left_on='prev_tx_id',right_on='txid')\n",
    "#a=a.merge(transactions[['txid','timestamp']],left_on='txid_x',right_on='txid')[['prev_tx_id','timestamp_x','prev_tx_pos','txid','timestamp_y']]\n",
    "\n",
    "created_tx_ts=inputs.merge(transactions[['txid','timestamp']],left_on='prev_tx_id',right_on='txid')\n",
    "\n",
    "spent_tx_ts=inputs.merge(transactions[['txid','timestamp']],left_on='txid',right_on='txid')\n",
    "\n",
    "average_utxo_dt=pd.DataFrame()\n",
    "\n",
    "average_utxo_dt['deltatime']=pd.to_timedelta(spent_tx_ts['timestamp']-created_tx_ts['timestamp'],unit='s')\n",
    "average_utxo_dt=average_utxo_dt.groupby('deltatime',group_keys=True).apply(lambda x: len(x))\n",
    "# TODO: finish data display"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## distribuzione del numero di input e output impiegati per le transazioni\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_count=inputs.groupby('txid').count()\n",
    "output_count=outputs.groupby('txid').count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 clusterizzazione degli indirizzi di bitcoin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 1\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\"\"\"\n",
    "considerare le transazioni che hanno un numero di input\n",
    "maggiore di 1 e associare ad uno stesso utente tutti gli indirizzi utilizzati negli input della stessa\n",
    "transazione.\n",
    "\"\"\"\n",
    "#associo ad ogni input l'output speso per  ottenere l'indirizzo corrispondente\n",
    "tx_addresses=inputs.merge(outputs,how='inner',left_on=['prev_tx_id','prev_tx_pos'],right_on=['txid','position'])[['prev_tx_id','address_id']]\n",
    "#tx_addresses=tx_addresses.merge(map)\n",
    "tx_addresses=tx_addresses.groupby(['prev_tx_id'])\n",
    "print('done 1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\katyg\\AppData\\Local\\Temp\\ipykernel_7276\\3852097859.py:5: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for k,group in islice(tx_addresses,10000):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 2\n",
      "numero di nodi 59\n",
      "numero di archi 39\n",
      "7 2 2.6818181818181817\n",
      "defaultdict(<function <lambda> at 0x000001B075280790>, {4: 2, 3: 3, 2: 15, 5: 1, 7: 1})\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "from collections import defaultdict\n",
    "g=nx.DiGraph()\n",
    "#TODO : fix dataset\n",
    "for k,group in islice(tx_addresses,10000):\n",
    "    if(len(group)<=1):\n",
    "        pass\n",
    "    a=group['address_id']\n",
    "    u,*v=a.to_list()\n",
    "    for _v in v:\n",
    "        g.add_edge(map.loc[u].hash,map.loc[_v].hash)\n",
    "print('done 2')\n",
    "wcg=list(nx.weakly_connected_components(g))\n",
    "print(\"numero di nodi \"+str(g.number_of_nodes() ))\n",
    "print(\"numero di archi \"+str(g.number_of_edges()))\n",
    "cluster_sizes=[ len(x) for x in wcg]\n",
    "print(max(cluster_sizes),min(cluster_sizes),sum(cluster_sizes)/len(cluster_sizes))\n",
    "cluster_stats=defaultdict(lambda:0)\n",
    "for x in cluster_sizes:\n",
    "    cluster_stats[x]+=1\n",
    "print(cluster_stats)\n",
    "first_ten_clusters={ k:v for (k,v) in  enumerate(sorted(wcg,key=len,reverse=True)[0:10])}\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deanonimizzazione\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'defaultdict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbs4\u001b[39;00m \u001b[39mimport\u001b[39;00m BeautifulSoup\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrequests\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m identity_dict\u001b[39m=\u001b[39mdefaultdict(\u001b[39mlambda\u001b[39;00m:\u001b[39mset\u001b[39m())\n\u001b[0;32m      5\u001b[0m \u001b[39m#scraping ddi wallet explorer\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m cluster \u001b[39min\u001b[39;00m first_ten_clusters\u001b[39m.\u001b[39mvalues():\n",
      "\u001b[1;31mNameError\u001b[0m: name 'defaultdict' is not defined"
     ]
    }
   ],
   "source": [
    "# wallet explorer\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "identity_dict=defaultdict(lambda:set())\n",
    "#scraping ddi wallet explorer\n",
    "for cluster in first_ten_clusters.values():\n",
    "    for address in cluster:\n",
    "        page=requests.get(\"https://www.walletexplorer.com/\",{'q':address}).text\n",
    "        bs = BeautifulSoup(page,'html.parser')\n",
    "        try:\n",
    "            wallet=bs.find('h2').find_all(text=True)[1][1:-2]\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        if wallet != None:\n",
    "            identity_dict[wallet]=identity_dict[wallet].union(cluster)\n",
    "            break\n",
    "# scraping di bitcoin info-charts\n",
    "#cambio parametro user-agent per evitare i controlli anti web-scraping\n",
    "headers={\n",
    "    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/113.0'\n",
    "}\n",
    "\n",
    "for cluster in first_ten_clusters.values():\n",
    "    for address in cluster:\n",
    "        req = requests.get(f\"https://bitinfocharts.com/bitcoin/address/{address}\",headers=headers)\n",
    "        bs = BeautifulSoup(req.text,'html.parser')\n",
    "        try:\n",
    "            wallet=bs.find(lambda x: (\"wallet\" in x.text) and x.name=='a').text.split(' ')[1]\n",
    "        except AttributeError:\n",
    "            print('indirizzo '+address+' non deanonimizzato')\n",
    "            break\n",
    "        \n",
    "        identity_dict[wallet]=identity_dict[wallet].union(cluster)\n",
    "identity_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
